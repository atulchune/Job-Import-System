# ğŸ—‚ï¸ Job Import History Tracking System

A full-stack project using **Node.js**, **Next.js**, **MongoDB**, and **Bull (Redis)** to fetch, process, and track job listings from RSS feeds. This system automatically stores and updates jobs in the database and maintains a detailed log of each import for dashboard display and analytics.

---

## ğŸš€ Features

- ğŸ“° Fetch job listings from multiple RSS feed sources.
- âš™ï¸ Normalize and store data in MongoDB using Mongoose.
- ğŸ§± Queue each job using Bull (Redis) for asynchronous processing.
- ğŸ” Upsert jobs by `guid` or `jobid` (insert if new, update if exists).
- ğŸ§¾ Import logs track total, new, updated, and failed jobs per run.
- â° Cron-based scheduler runs fetch jobs every few minutes/hours.
- ğŸ“Š View paginated logs and stats on a frontend dashboard.

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ controllers/       # Route logic (logs, dashboard stats)
â”‚   â”œâ”€â”€ models/            # Mongoose schemas (Job, ImportLog)
â”‚   â”œâ”€â”€ queue/             # Bull Redis setup and processing
â”‚   â”œâ”€â”€ routes/            # Express API endpoints
â”‚   â”œâ”€â”€ utils/             # XML parser, cleaner, fetcher
â”‚   â”œâ”€â”€ server.js          # Main Express app
â”‚   â”œâ”€â”€ .env               # Environment config
|   â””â”€â”€ package.json           # Shared dependencies / root scripts
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/        # UI components (tables, cards)
â”‚   â”œâ”€â”€ pages/             # Next.js pages
â”‚   â”œâ”€â”€ utils/             # API calls, date formatting
â”‚   â”œâ”€â”€ public/            # Static files (icons, assets)
â”‚   â”œâ”€â”€ .env               # Environment config
|   â””â”€â”€ package.json           # Shared dependencies / root scripts
â”œâ”€â”€ README.md              # Project documentation
```

---

## ğŸ§° Tech Stack

| Layer       | Tech Used                  |
|-------------|----------------------------|
| Frontend    | Next.js, React, Tailwind   |
| Backend     | Node.js, Express.js        |
| Database    | MongoDB + Mongoose         |
| Queue       | Bull with Redis Cloud      |
| Parser      | xml2js for RSS/Atom feeds  |
| Scheduler   | node-cron                  |
| Deployment  | Render (backend), Vercel (frontend)

---
```
## ğŸ”„Import Flow Diagram

External RSS/XML Feeds
        â†“
Axios fetch + XML â†’ JSON parse
        â†“
Jobs pushed into Redis Queue (Bull)
        â†“
Worker consumes jobs asynchronously
        â†“
MongoDB: Insert / Update Job Collection
        â†“
Import Log Created in import_logs collection
```
## âš™ï¸ Setup Instructions
Clone the Repository

```bash
git clone https://github.com/atulchune/job-import-tracker.git
cd job-import-tracker

### ğŸ“Œ Prerequisites
- Node.js 18+
- Redis (local or Redis Cloud)
- MongoDB instance (local or MongoDB Atlas)

### ğŸ”§ Backend Setup

```bash
cd backend
npm install
```

**.env**
```env
PORT=5000
MONGO_URI=mongodb://localhost:27017/import-tracker
REDIS_URL=redis://default:<password>@<host>:<port>
```

Start the backend:

```bash
npm start
```

### ğŸ’» Frontend Setup

```bash
cd frontend
npm install
```

**.env**
```env
NEXT_PUBLIC_BACKEND_URL=http://localhost:5000
```

Run frontend:

```bash
npm run dev
```

---

## ğŸ”‘ Key Logic & Architecture

### ğŸ§  Job Import Flow:
1. **Feeds** are fetched using `axios` and converted from XML to JSON.
2. Each job is **normalized** with consistent fields like `guid`, `pubDate`, `title`, etc.
3. Jobs are **queued** into Bull (`jobQueue`).
4. A **worker** consumes the queue, updating or inserting each job into MongoDB.
5. Import **summary statistics** (inserted, updated, failed) are logged into `ImportLog`.

### ğŸ§° Tools Used:
- **Express.js** â€“ REST API backend
- **Next.js** â€“ Frontend with dynamic pages
- **MongoDB** â€“ Persistent job storage
- **Bull + Redis** â€“ Queue and background processing
- **node-cron** â€“ Scheduled job import
- **axios + fast-xml-parser** â€“ XML feed handling

---

## ğŸ”— API Endpoints

### ğŸ§¾ Import Logs

### ğŸ“¡ API Endpoints

| Method | Endpoint                             | Description                          |
|--------|--------------------------------------|--------------------------------------|
| GET    | `/api/import_logs?page=1&limit=10`   | Fetch paginated import log entries   |
| GET    | `/api/dashboard_counts`              | Fetch dashboard summary counts       |


---

## ğŸ“Œ Assumptions

- All job feeds are RSS-based and contain `guid`, `title`, `description`, and `pubDate`.
- No authentication layer is required for viewing logs.
- Redis and MongoDB services are available and properly configured.
- The frontend and backend are hosted under different subdomains or ports.

---

## ğŸ”® Future Enhancements

- ğŸ” Add authentication and roles (admin, viewer)
- ğŸ“¤ Add job export to CSV/Excel
- ğŸ•µï¸â€â™€ï¸ Detailed view of failed jobs
- ğŸ“… Scheduling UI to trigger re-fetch
- ğŸŒ Support more feed types (Atom, JSON feeds)
- ğŸ“ˆ Add charts for trends (e.g., new jobs/week)

---

## ğŸ™Œ Author

Made with â¤ï¸ by Atul Chune

